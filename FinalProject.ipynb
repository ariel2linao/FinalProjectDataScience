{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fabd822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in e:\\anaconda\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: boto3 in e:\\anaconda\\lib\\site-packages (1.24.28)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in e:\\anaconda\\lib\\site-packages (from boto3) (1.27.28)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in e:\\anaconda\\lib\\site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in e:\\anaconda\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in e:\\anaconda\\lib\\site-packages (from botocore<1.28.0,>=1.27.28->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in e:\\anaconda\\lib\\site-packages (from botocore<1.28.0,>=1.27.28->boto3) (1.26.11)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.28->boto3) (1.16.0)\n",
      "Requirement already satisfied: bs4 in e:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in e:\\anaconda\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install boto3\n",
    "!pip install bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee08a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import bs4\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db42470",
   "metadata": {},
   "source": [
    "## Define a Web Scraping Function <br>\n",
    "\n",
    "In this section, we define the function get_basketball_stats. The function will return a dictionary corresponding to the Regular season statistics of each basketball player scraped from m en.wikipedia.org. The Formal Parameter or input  link is going to be the URL of the Wikipedia page for each player. This function will return a Python dictionary. The keys will be the column names, and the values will be a list that contains a different columns; the element of each list will be a separate row for that column. You don't have to know how the function works just the input in the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce231678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basketball_stats(link='https://en.wikipedia.org/wiki/Michael_Jordan'):\n",
    "    # read the webpage \n",
    "    response = requests.get(link)\n",
    "    # create a BeautifulSoup object to parse the HTML  \n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    # the player stats are defined  with the attribute CSS class set to 'wikitable sortable'; \n",
    "    #therefore we create a tag object \"table\"\n",
    "    table=soup.find(class_='wikitable sortable')\n",
    "\n",
    "    #the headers of the table are the first table row (tr) we create a tag object that has the first row  \n",
    "    headers=table.tr\n",
    "    #the table column names are displayed  as an abbreviation; therefore we find all the abbr tags and returs an Iterator\n",
    "    titles=headers.find_all(\"abbr\")\n",
    "    #we create a dictionary  and pass the table headers as the keys \n",
    "    data = {title['title']:[] for title in titles}\n",
    "   #we will store each column as a list in a dictionary, the header of the column will be the dictionary key \n",
    "\n",
    "    #we iterate over each table row by fining each table tag tr and assign it to the objed\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "    \n",
    "        #we iterate over each cell in the table, as each cell corresponds to a different column we all obtain the correspondin key corresponding the column n \n",
    "        for key,a in zip(data.keys(),row.find_all(\"td\")[2:]):\n",
    "            # we append each elment and strip any extra HTML contnet \n",
    "            data[key].append(''.join(c for c in a.text if (c.isdigit() or c == \".\")))\n",
    "\n",
    "    # we remove extra rows by finding the smallest list     \n",
    "    Min=min([len(x)  for x in data.values()])\n",
    "    #we convert the elements in the key to floats \n",
    "    for key in data.keys():\n",
    "    \n",
    "        data[key]=list(map(lambda x: float(x), data[key][:Min]))\n",
    "       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a370a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basketball_stats(link='https://en.wikipedia.org/wiki/Kobe_Bryant'):\n",
    "    # read the webpage \n",
    "    response = requests.get(link)\n",
    "    # create a BeautifulSoup object to parse the HTML  \n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    # the player stats are defined  with the attribute CSS class set to 'wikitable sortable'; \n",
    "    #therefore we create a tag object \"table\"\n",
    "    table=soup.find(class_='wikitable sortable')\n",
    "\n",
    "    #the headers of the table are the first table row (tr) we create a tag object that has the first row  \n",
    "    headers=table.tr\n",
    "    #the table column names are displayed  as an abbreviation; therefore we find all the abbr tags and returs an Iterator\n",
    "    titles=headers.find_all(\"abbr\")\n",
    "    #we create a dictionary  and pass the table headers as the keys \n",
    "    data = {title['title']:[] for title in titles}\n",
    "   #we will store each column as a list in a dictionary, the header of the column will be the dictionary key \n",
    "\n",
    "    #we iterate over each table row by fining each table tag tr and assign it to the objed\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "    \n",
    "        #we iterate over each cell in the table, as each cell corresponds to a different column we all obtain the correspondin key corresponding the column n \n",
    "        for key,a in zip(data.keys(),row.find_all(\"td\")[2:]):\n",
    "            # we append each elment and strip any extra HTML contnet \n",
    "            data[key].append(''.join(c for c in a.text if (c.isdigit() or c == \".\")))\n",
    "\n",
    "    # we remove extra rows by finding the smallest list     \n",
    "    Min=min([len(x)  for x in data.values()])\n",
    "    #we convert the elements in the key to floats \n",
    "    for key in data.keys():\n",
    "    \n",
    "        data[key]=list(map(lambda x: float(x), data[key][:Min]))\n",
    "       \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4498985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basketball_stats(link='https://en.wikipedia.org/wiki/LeBron_James'):\n",
    "    # read the webpage \n",
    "    response = requests.get(link)\n",
    "    # create a BeautifulSoup object to parse the HTML  \n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    # the player stats are defined  with the attribute CSS class set to 'wikitable sortable'; \n",
    "    #therefore we create a tag object \"table\"\n",
    "    table=soup.find(class_='wikitable sortable')\n",
    "\n",
    "    #the headers of the table are the first table row (tr) we create a tag object that has the first row  \n",
    "    headers=table.tr\n",
    "    #the table column names are displayed  as an abbreviation; therefore we find all the abbr tags and returs an Iterator\n",
    "    titles=headers.find_all(\"abbr\")\n",
    "    #we create a dictionary  and pass the table headers as the keys \n",
    "    data = {title['title']:[] for title in titles}\n",
    "   #we will store each column as a list in a dictionary, the header of the column will be the dictionary key \n",
    "\n",
    "    #we iterate over each table row by fining each table tag tr and assign it to the objed\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "    \n",
    "        #we iterate over each cell in the table, as each cell corresponds to a different column we all obtain the correspondin key corresponding the column n \n",
    "        for key,a in zip(data.keys(),row.find_all(\"td\")[2:]):\n",
    "            # we append each elment and strip any extra HTML contnet \n",
    "            data[key].append(''.join(c for c in a.text if (c.isdigit() or c == \".\")))\n",
    "\n",
    "    # we remove extra rows by finding the smallest list     \n",
    "    Min=min([len(x)  for x in data.values()])\n",
    "    #we convert the elements in the key to floats \n",
    "    for key in data.keys():\n",
    "    \n",
    "        data[key]=list(map(lambda x: float(x), data[key][:Min]))\n",
    "       \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a37a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basketball_stats(link='https://en.wikipedia.org/wiki/Stephen_Curry'):\n",
    "    # read the webpage \n",
    "    response = requests.get(link)\n",
    "    # create a BeautifulSoup object to parse the HTML  \n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    # the player stats are defined  with the attribute CSS class set to 'wikitable sortable'; \n",
    "    #therefore we create a tag object \"table\"\n",
    "    table=soup.find(class_='wikitable sortable')\n",
    "\n",
    "    #the headers of the table are the first table row (tr) we create a tag object that has the first row  \n",
    "    headers=table.tr\n",
    "    #the table column names are displayed  as an abbreviation; therefore we find all the abbr tags and returs an Iterator\n",
    "    titles=headers.find_all(\"abbr\")\n",
    "    #we create a dictionary  and pass the table headers as the keys \n",
    "    data = {title['title']:[] for title in titles}\n",
    "   #we will store each column as a list in a dictionary, the header of the column will be the dictionary key \n",
    "\n",
    "    #we iterate over each table row by fining each table tag tr and assign it to the objed\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "    \n",
    "        #we iterate over each cell in the table, as each cell corresponds to a different column we all obtain the correspondin key corresponding the column n \n",
    "        for key,a in zip(data.keys(),row.find_all(\"td\")[2:]):\n",
    "            # we append each elment and strip any extra HTML contnet \n",
    "            data[key].append(''.join(c for c in a.text if (c.isdigit() or c == \".\")))\n",
    "\n",
    "    # we remove extra rows by finding the smallest list     \n",
    "    Min=min([len(x)  for x in data.values()])\n",
    "    #we convert the elements in the key to floats \n",
    "    for key in data.keys():\n",
    "    \n",
    "        data[key]=list(map(lambda x: float(x), data[key][:Min]))\n",
    "       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1cf5ea",
   "metadata": {},
   "source": [
    "## Question 1: Web Scraping the data and Converting to Pandas Dataframe <br>\n",
    "For this question, you must use the function get_basketball_stats to extract a Python Dictionary of the player statistics, convert the dictionary to a Python Dataframe. To get full marks, you must display the first five rows of the dataframe for each player using the method head with the name of each player printed above. As shown in the following figuer the order of the columns may be different depending on the version of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d328a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3891bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "links=['https://en.wikipedia.org/wiki/Michael_Jordan'\\\n",
    "       ,'https://en.wikipedia.org/wiki/Kobe_Bryant'\\\n",
    "      ,'https://en.wikipedia.org/wiki/LeBron_James'\\\n",
    "      \n",
    "      ,'https://en.wikipedia.org/wiki/Stephen_Curry']\n",
    "names=['Michael Jordan','Kobe Bryant','Lebron James','Stephen Curry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fbae31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_jordan_dict=get_basketball_stats('https://en.wikipedia.org/wiki/Michael_Jordan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f089196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_jordan_dict=get_basketball_stats(links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d09147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mj_dict=get_basketball_stats(links[0])\n",
    "kb_dict=get_basketball_stats(links[1])\n",
    "lj_dict=get_basketball_stats(links[2])\n",
    "sc_dict=get_basketball_stats(links[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b6ee6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mj_df = pd.DataFrame.from_dict(mj_dict)\n",
    "kb_df = pd.DataFrame.from_dict(kb_dict)\n",
    "lj_df = pd.DataFrame.from_dict(lj_dict)\n",
    "sc_df = pd.DataFrame.from_dict(sc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a359ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for name in names:\n",
    "    current_dict=get_basketball_stats(links[i])\n",
    "    df = pd.DataFrame(current_dict)\n",
    "    print(name)\n",
    "    display(df)\n",
    "    print(\" \\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a13a29",
   "metadata": {},
   "source": [
    "## Question 2: plot the Points per game for a player using the function plt.plot(). <br>\n",
    "\n",
    "Import the plotting library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda95c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[['Points per game']],label=name)\n",
    "plt.legend()\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Points per game')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018532ce",
   "metadata": {},
   "source": [
    "## Question 3: Store the Player Statistics in Object Storage (optional). <br>\n",
    "\n",
    "Save one player's dataframe as a csv file using the method dataframe.to_csv(csv_name). The string that contains the name of the csv file should be assigned the csv_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"finaldatascienceprojectwithpython\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c233ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = 'SC1.csv'\n",
    "df.to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ef221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "Michael_jordan_dict=get_basketball_stats(links[0])\n",
    "Kobe_bryant_dict = get_basketball_stats(links[1])\n",
    "Lebron_james_dict =get_basketball_stats(links[2])\n",
    "Stephen_curry_dict = get_basketball_stats(links[3])\n",
    "mj_df = pd.DataFrame.from_dict(Michael_jordan_dict)\n",
    "kb_df = pd.DataFrame.from_dict(Kobe_bryant_dict)\n",
    "lj_df = pd.DataFrame.from_dict(Lebron_james_dict)\n",
    "sc_df = pd.DataFrame.from_dict(Stephen_curry_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded3625",
   "metadata": {},
   "source": [
    "\n",
    "    dict=get_basketball_stats(links[a])\n",
    "    data_frame = pd.DataFrame.from_dict(dict)\n",
    "    name = names[a]\n",
    "    plt.plot(data_frame[['Points per game']],label=name)\n",
    "    plt.legend()\n",
    "    plt.xlabel('years')\n",
    "    plt.ylabel('Points per game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe55b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = 'MJ1.csv'\n",
    "mj_df.to_csv(csv_name)\n",
    "csv_name = 'KB1.csv'\n",
    "kb_df.to_csv(csv_name)\n",
    "csv_name = 'LJ1.csv'\n",
    "lj_df.to_csv(csv_name)\n",
    "csv_name = 'SC1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed293ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
